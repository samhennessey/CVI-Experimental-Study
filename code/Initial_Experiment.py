from CVIs import *
from methods import *
from helper import *
from randomised_normal import *
from results_helper import *
import json
from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score
import matplotlib as mpl


CONSTRAINT_PERCENTAGE = 0.2 # What percentage of |data| to generate as constraints
MAX_CLUSTERS = 28 # max K

# Results information...
RESULTS_LOCATION = './results/RealData' # where the results should be stored
FOLDER_RE = '^Data_+' # regular experssion of the folders within the results
CI = 0.95 # confidence interval of the results

# dataset characteristics
DATA_WIDTH = 40
NO_CLUSTERS = 7
DATA_DIMS = 3

# clustering methods
CLUSTERING_METHDOS = [K_means, single_linkage, LCCV_HC]
ALG = [alg.__name__ for alg in CLUSTERING_METHDOS]

# internal CVIS
CVIS = [NH ,norm_sil, satC, satC_NH, satC_sil, satC_comb]#, satC_LCCV ,satC_multi_sil, satC_muli_comb, satC_sil_pNH, satC_NH_sil_add, satC_mComb]
 # sat_split, sat_split_sil, sat_split_NH_sil, sat_split_multi_comb,LCCV_index, norm_sil, NH]
cvis = [cvi.__name__ for cvi in CVIS]

# range of Np
# RUNS = np.arange(100,1000,50)

# Datasets folder location
DS_FOLDER = './SyntheticDataSets/RealData/'

if __name__ == '__main__':

    # get a list of all datasets....
    datasets = get_datasets(DS_FOLDER)
    '''FOR FRANKS METHOD -> CREATE A RANGE FOR N -> [100, 1000, 100]'''
    for ds in datasets:
    # for Np in RUNS:
        '''TO USE FRANKS FUNCTIONS FOR THE DATASETS GENERATOR

        D, L = randomised_normal(DATA_WIDTH, np.random.randint(2,MAX_CLUSTERS), Np, DATA_DIMS)
        '''

        D, L = load_data(ds)

        # For the datasets generated in matlab
        if np.min(L) == 1:
            L = L - 1 

        N,n = D.shape
        
        # Get the name of the dataset without the filepath and extension at the end
        ds_name = os.path.basename(ds)
        index_of_dot = ds_name.index('.')
        ds_without_extension = ds_name[:index_of_dot]

        DS_LOC = RESULTS_LOCATION + '/'+ ds_without_extension # Save location for the current dataset -> ./results/DS.__name.__        

        ML, CL = random_constraint_generation(D, L, CONSTRAINT_PERCENTAGE) # Generate the constraints from the labels

        K_RANGE = np.arange(2, MAX_CLUSTERS + 1)

        cm_ind = 0
        for cm in CLUSTERING_METHDOS:
            P_SAVE_LOC = DS_LOC + '/' + cm.__name__  # save location for the clustering method on the datasets -> ./results/DS.__name.__/cm.__name__
            cm_vars = cm.__code__.co_varnames
            CM_RESULTS = np.empty((N,len(K_RANGE))) # store the generated partions for each K for the algorithm

            # Perform LCCV_HC clustering here as the values of K changes within the algorithm
            if cm.__name__ == 'LCCV_HC':
                LCCV_best_P, _, LCCV_HC_results = LCCV_HC(D)

            # Calculate the partitions for varying K
            for K in K_RANGE:
                if cm.__name__ == 'LCCV_HC':
                    for key in LCCV_HC_results.keys():
                        if 'clunum' in LCCV_HC_results[key].keys():
                            if LCCV_HC_results[key]['clunum'] == K:
                                P = LCCV_HC_results[key]['cl']
                else:
                    if 'ML' and 'CL' in cm_vars:
                        P = cm(D, K, ML, CL)
                    else:
                        P = cm(D, K)

                if np.min(P) == 1:
                    P = P-1

                CM_RESULTS[:,K-2] = P

            # For each CVI calculate the values of the partiions generated by the algorithm
            cvi_ind = 0 # used for plotting
            for cvi in CVIS:
                CVI_LOC = P_SAVE_LOC + '/' + cvi.__name__ # Save the outputed values of each CVI -> ./results/DS.__name.__/cm.__name__/cvi.__name
                cvi_vars = cvi.__code__.co_varnames
                CVI_RESULTS = np.empty(len(K_RANGE))
                for K in K_RANGE:
                    if 'ML' and 'CL' in cvi_vars:
                        if 'data' not in cvi_vars:
                            cvi_val = cvi(CM_RESULTS[:,K-2], ML, CL)
                        else:
                            cvi_val = cvi(D, CM_RESULTS[:,K-2], ML, CL)
                    else:
                        cvi_val = cvi(D,CM_RESULTS[:,K-2])

                    CVI_RESULTS[K-2] = cvi_val
                
                # Save the CVI values in the folder './results/Np/cm/cvi/cvi_values.csv'
                try:
                    np.savetxt(CVI_LOC + '/cvi_values.csv', CVI_RESULTS, fmt='%f' ,delimiter=",")
                except FileNotFoundError:
                    os.makedirs(CVI_LOC + '/')
                    np.savetxt(CVI_LOC + '/cvi_values.csv', CVI_RESULTS, fmt='%f' ,delimiter=",")

                # Find the best partition for each cvi and calculate the 
                best_cvi_index = np.argmax(CVI_RESULTS)
                best_P = CM_RESULTS[:,best_cvi_index]

                NMI_partition = normalized_mutual_info_score(L.flatten(),best_P)
                ARI = (adjusted_rand_score(L.flatten(), best_P) + 0.5)/1.5 # value between -0.5 -> 1 

                partition_results = {'BEST_P':list(best_P), 'NMI':NMI_partition, 'ARI':ARI} 

                # Save the best partition according to the CVI value. along with the NMI of the partition with the true labels 
                with open(CVI_LOC + "/best_partition.txt", "w") as fp:
                    json.dump(partition_results, fp)  # encode dict into JSON

                cvi_ind += 1 # used for plotting

            np.savetxt(P_SAVE_LOC + '/partitions.csv', CM_RESULTS, fmt='%f' ,delimiter=",")

            cm_ind += 1

    display_results(RESULTS_LOCATION, FOLDER_RE, ALG, np.arange(len(datasets)), cvis, CI)


            
            
            
        
        
        

                
                
                
                 



